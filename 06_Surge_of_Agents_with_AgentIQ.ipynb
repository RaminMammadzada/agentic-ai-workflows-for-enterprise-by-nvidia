{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/nvidia_header.png\" style=\"margin-left: -30px; width: 300px; float: left;\"> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Surge of Agents with AgentIQ: Integrating Multiple AI Frameworks\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to this hands-on tutorial on integrating multiple AI frameworks with AgentIQ! In this notebook, we'll transform the \"Surge of Agents\" example into an AgentIQ workflow that orchestrates four powerful frameworks:\n",
    "\n",
    "- **OpenAI Python Library**: For direct access to language models with a clean API\n",
    "- **LangChain**: For structured data handling and composable processing chains\n",
    "- **LangGraph**: For graph-based workflow management with modular components\n",
    "- **CrewAI**: For collaborative multi-agent orchestration with specialized roles\n",
    "\n",
    "The key insight of this tutorial is that **you don't need to rewrite your existing code** to benefit from AgentIQ's orchestration capabilities. Instead, we'll create thin wrapper components that integrate your framework-specific code into a unified workflow.\n",
    "\n",
    "By the end of this notebook, you'll understand how to:\n",
    "1. Create AgentIQ components that wrap existing framework code\n",
    "2. Configure a workflow that connects these components\n",
    "3. Run the workflow as a unified system\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "Before diving into the frameworks, we need to establish our development environment. We'll configure access to the NVIDIA AI Foundation Models platform, which provides access to powerful open-source models like Llama 3.1.\n",
    "\n",
    "### Key Configuration Elements:\n",
    "\n",
    "- **API Key**: The authentication token required to access NVIDIA's API services. In production environments, this should be stored securely as an environment variable rather than hardcoded in your notebooks.\n",
    "\n",
    "- **Endpoint URL**: The base URL that directs our requests to NVIDIA's AI model serving infrastructure. This endpoint handles all communication between our code and the foundation models.\n",
    "\n",
    "- **Model Selection**: We're using `meta/llama-3.1-70b-instruct`, a powerful open-source LLM that balances performance and efficiency contained in an NVIDIA NIM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by setting up these configuration parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "endpoint_url = os.getenv(\"NVIDIA_BASE_URL\")\n",
    "model_name = \"meta/llama-3.1-70b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1: Project Setup\n",
    "\n",
    "Now we'll create the project structure for our AgentIQ workflow. We'll use the AgentIQ CLI to create a new workflow and set up the necessary directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow 'surge_of_agents' created successfully in '/dli/task/workflows/surge_of_agents'.\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Create the workflows directory if it doesn't exist\n",
    "!mkdir -p workflows\n",
    "\n",
    "# Create a new AgentIQ workflow\n",
    "!aiq workflow create --no-install --workflow-dir workflows surge_of_agents\n",
    "\n",
    "# Create additional directories for configs and data\n",
    "!mkdir -p workflows/surge_of_agents/configs\n",
    "!mkdir -p workflows/surge_of_agents/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the project structure that was created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34mworkflows/surge_of_agents\u001b[0m\n",
      "├── \u001b[01;34mconfigs\u001b[0m\n",
      "│   └── \u001b[01;36mconfig.yml\u001b[0m -> \u001b[00m/dli/task/workflows/surge_of_agents/src/surge_of_agents/configs/config.yml\u001b[0m\n",
      "├── \u001b[01;34mdata\u001b[0m\n",
      "├── \u001b[00mpyproject.toml\u001b[0m\n",
      "└── \u001b[01;34msrc\u001b[0m\n",
      "    └── \u001b[01;34msurge_of_agents\u001b[0m\n",
      "        ├── \u001b[00m__init__.py\u001b[0m\n",
      "        ├── \u001b[01;34mconfigs\u001b[0m\n",
      "        │   └── \u001b[00mconfig.yml\u001b[0m\n",
      "        ├── \u001b[00mregister.py\u001b[0m\n",
      "        └── \u001b[00msurge_of_agents_function.py\u001b[0m\n",
      "\n",
      "6 directories, 6 files\n"
     ]
    }
   ],
   "source": [
    "# List the project structure\n",
    "!tree workflows/surge_of_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AgentIQ CLI has created a basic project structure with:\n",
    "- `pyproject.toml`: Package configuration file\n",
    "- `src/surge_of_agents/`: Source directory for our components\n",
    "  - `__init__.py`: Package initialization file\n",
    "  - `register.py`: Component registration file\n",
    "  - `surge_of_agents_function.py`: Default AgentIQ component file\n",
    "\n",
    "Now, let's update the `pyproject.toml` file to include the dependencies we need for our multi-framework integration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workflows/surge_of_agents/pyproject.toml\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/pyproject.toml\n",
    "[build-system]\n",
    "build-backend = \"setuptools.build_meta\"\n",
    "requires = [\"setuptools >= 64\"]\n",
    "\n",
    "[project]\n",
    "name = \"surge_of_agents\"\n",
    "version = \"0.1.0\"\n",
    "dependencies = [\n",
    "  \"agentiq[langchain,llama-index]\",\n",
    "  \"openai\",\n",
    "  \"langchain\",\n",
    "  \"langchain_nvidia_ai_endpoints\",\n",
    "  \"langgraph\",\n",
    "  \"crewai\",\n",
    "  \"pydantic\"\n",
    "]\n",
    "requires-python = \">=3.12\"\n",
    "description = \"AgentIQ workflow integrating multiple AI frameworks\"\n",
    "classifiers = [\"Programming Language :: Python\"]\n",
    "\n",
    "[project.entry-points.\"aiq.components\"]\n",
    "surge_of_agents = \"surge_of_agents.register\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2: Framework Component Wrappers\n",
    "\n",
    "Now we'll create wrapper components for each of the four frameworks. These wrappers will allow us to integrate existing framework-specific code into our AgentIQ workflow without rewriting it.\n",
    "\n",
    "### 1. OpenAI Wrapper Component\n",
    "\n",
    "First, let's create a wrapper for the OpenAI Python library that generates math equations. This component will:\n",
    "1. Use the OpenAI client to access the NVIDIA API\n",
    "2. Generate a math equation suitable for pre-algebra students\n",
    "3. Return the equation as output\n",
    "\n",
    "Let's create this component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workflows/surge_of_agents/src/surge_of_agents/openai_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/src/surge_of_agents/openai_wrapper.py\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "from aiq.builder.builder import Builder\n",
    "from aiq.builder.function_info import FunctionInfo\n",
    "from aiq.cli.register_workflow import register_function\n",
    "from aiq.data_models.function import FunctionBaseConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EquationGeneratorConfig(FunctionBaseConfig, name=\"equation_generator\"):\n",
    "    \"\"\"Configuration for the equation generator component.\"\"\"\n",
    "    endpoint_url: str = os.getenv(\"NVIDIA_BASE_URL\")\n",
    "    model_name: str = \"meta/llama-3.1-70b-instruct\"\n",
    "    temperature: float = 0.5\n",
    "\n",
    "@register_function(config_type=EquationGeneratorConfig)\n",
    "async def equation_generator(config: EquationGeneratorConfig, builder: Builder):\n",
    "    \"\"\"\n",
    "    A wrapper for the OpenAI Python library that generates math equations.\n",
    "    \"\"\"\n",
    "    from openai import OpenAI\n",
    "    import os\n",
    "\n",
    "    async def _generate_equation(student_level: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate a math equation using the OpenAI API.\n",
    "        \n",
    "        Args:\n",
    "            student_level: The student level of the equation, such as \"pre-algebra\", \"algebra\", \"geometry\", or \"calculus\"\n",
    "            \n",
    "        Returns:\n",
    "            A dictionary containing the generated equation\n",
    "        \"\"\"\n",
    "        # Initialize the OpenAI client\n",
    "        client = OpenAI(\n",
    "            organization=\"nvidia\",\n",
    "            base_url=config.endpoint_url,\n",
    "            api_key=os.getenv(\"NVIDIA_API_KEY\"),\n",
    "        )\n",
    "        \n",
    "        # Create the prompt based on student_level\n",
    "        prompt = f\"\"\"\n",
    "        Create a math equation suitable for a {student_level} student that involves solving for a single variable, x.\n",
    "        Provide only the equation, like \"3x - 5 = 10\".\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate the equation\n",
    "        response = client.chat.completions.create(\n",
    "            model=config.model_name,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=config.temperature\n",
    "        )\n",
    "        \n",
    "        # Extract and return the equation\n",
    "        equation = response.choices[0].message.content.strip()\n",
    "        return {\"equation\": equation}\n",
    "\n",
    "    yield FunctionInfo.from_fn(\n",
    "        _generate_equation,\n",
    "        description=\"Generates math equations of varying difficulty levels using the OpenAI API\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LangChain Wrapper Component\n",
    "\n",
    "Next, let's create a wrapper for LangChain that generates word problems from equations. This component will:\n",
    "1. Use LangChain's prompt templates and output parsers\n",
    "2. Create a structured workflow using the pipeline operator\n",
    "3. Return a word problem that matches the given equation\n",
    "\n",
    "Let's create this component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workflows/surge_of_agents/src/surge_of_agents/langchain_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/src/surge_of_agents/langchain_wrapper.py\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "from aiq.builder.builder import Builder\n",
    "from aiq.builder.framework_enum import LLMFrameworkEnum\n",
    "from aiq.builder.function_info import FunctionInfo\n",
    "from aiq.cli.register_workflow import register_function\n",
    "from aiq.data_models.component_ref import LLMRef\n",
    "from aiq.data_models.function import FunctionBaseConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class WordProblemGeneratorConfig(FunctionBaseConfig, name=\"word_problem_generator\"):\n",
    "    \"\"\"Configuration for the word problem generator component.\"\"\"\n",
    "    llm_name: LLMRef\n",
    "    debug_mode: bool = False\n",
    "\n",
    "@register_function(config_type=WordProblemGeneratorConfig, framework_wrappers=[LLMFrameworkEnum.LANGCHAIN])\n",
    "async def word_problem_generator(config: WordProblemGeneratorConfig, builder: Builder):\n",
    "    \"\"\"\n",
    "    A wrapper for LangChain that generates word problems from equations.\n",
    "    \"\"\"\n",
    "    from langchain.globals import set_debug\n",
    "    from langchain.output_parsers import PydanticOutputParser\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from pydantic import BaseModel, Field\n",
    "    \n",
    "    # Enable debug mode if requested\n",
    "    if config.debug_mode:\n",
    "        set_debug(True)\n",
    "    \n",
    "    # Get the LLM from the builder\n",
    "    llm = await builder.get_llm(config.llm_name, wrapper_type=LLMFrameworkEnum.LANGCHAIN)\n",
    "    \n",
    "    # Define a structured data model for word problems\n",
    "    class WordProblem(BaseModel):\n",
    "        word_problem: str = Field(description=\"The text of the math word problem\")\n",
    "    \n",
    "    # Create a parser that will extract structured data from LLM responses\n",
    "    word_problem_parser = PydanticOutputParser(pydantic_object=WordProblem)\n",
    "    \n",
    "    # Define a template for generating word problems with instructions for proper formatting\n",
    "    word_problem_prompt = PromptTemplate.from_template(\n",
    "        \"\"\"Given the equation {equation}, create a realistic word problem that matches it.\n",
    "        The problem should involve a real-world scenario (e.g., shopping, travel) and require solving for x.\n",
    "        Provide only the word problem.\n",
    "        Format your response as JSON: {format_instructions}. Do not include any other text but the JSON.\"\"\",\n",
    "        partial_variables={\"format_instructions\": word_problem_parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    # Compose the entire workflow as a chain using the pipeline operator\n",
    "    chain = word_problem_prompt | llm | word_problem_parser\n",
    "    \n",
    "    async def _generate_word_problem(equation: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Generate a word problem from an equation using LangChain.\n",
    "        \n",
    "        Args:\n",
    "            equation: The math equation to convert into a word problem\n",
    "            \n",
    "        Returns:\n",
    "            A dictionary containing the equation and generated word problem\n",
    "        \"\"\"\n",
    "        # Execute the chain with the equation\n",
    "        result = await chain.ainvoke({\"equation\": equation})\n",
    "        \n",
    "        # Return the equation and word problem\n",
    "        return {\n",
    "            \"equation\": equation,\n",
    "            \"word_problem\": result.word_problem\n",
    "        }\n",
    "    \n",
    "    yield FunctionInfo.from_fn(\n",
    "        _generate_word_problem,\n",
    "        description=\"Generates word problems from math equations using LangChain\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. LangGraph Wrapper Component\n",
    "\n",
    "Now, let's create a wrapper for LangGraph that solves the equation and explains the solution. This component will:\n",
    "1. Define nodes for solving and explaining\n",
    "2. Create a graph with connections between nodes\n",
    "3. Execute the graph to process the equation and word problem\n",
    "\n",
    "Let's create this component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workflows/surge_of_agents/src/surge_of_agents/langgraph_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/src/surge_of_agents/langgraph_wrapper.py\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "\n",
    "from aiq.builder.builder import Builder\n",
    "from aiq.builder.framework_enum import LLMFrameworkEnum\n",
    "from aiq.builder.function_info import FunctionInfo\n",
    "from aiq.cli.register_workflow import register_function\n",
    "from aiq.data_models.component_ref import LLMRef\n",
    "from aiq.data_models.function import FunctionBaseConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class EquationSolverConfig(FunctionBaseConfig, name=\"equation_solver\"):\n",
    "    \"\"\"Configuration for the equation solver component.\"\"\"\n",
    "    llm_name: LLMRef\n",
    "    debug_mode: bool = False\n",
    "\n",
    "@register_function(config_type=EquationSolverConfig, framework_wrappers=[LLMFrameworkEnum.LANGCHAIN])\n",
    "async def equation_solver(config: EquationSolverConfig, builder: Builder):\n",
    "    \"\"\"\n",
    "    A wrapper for LangGraph that solves equations and explains the solutions.\n",
    "    \"\"\"\n",
    "    from langchain.globals import set_debug\n",
    "    from langchain_core.prompts import PromptTemplate\n",
    "    from langgraph.graph import Graph, START\n",
    "    \n",
    "    # Enable debug mode if requested\n",
    "    if config.debug_mode:\n",
    "        set_debug(True)\n",
    "    \n",
    "    # Get the LLM from the builder\n",
    "    llm = await builder.get_llm(config.llm_name, wrapper_type=LLMFrameworkEnum.LANGCHAIN)\n",
    "    \n",
    "    # Create prompts for solving and explaining\n",
    "    equation_solver_prompt = PromptTemplate(\n",
    "        input_variables=[\"equation\", \"word_problem\"],\n",
    "        template=\"\"\"Given the equation {equation} and matching word problem {word_problem}, solve it by providing only the mathematical steps as a list.\n",
    "        Each part should be a single equation or expression, showing the progression to the final solution, without any explanatory text. For example, for \"5 + x = 13\", output:\n",
    "        5 + x = 13 -> x = 13 - 5 -> x = 8\"\"\"\n",
    "    )\n",
    "    \n",
    "    equation_solution_explainer_prompt = PromptTemplate(\n",
    "        input_variables=[\"equation\", \"word_problem\", \"solution\"],\n",
    "        template=\"\"\"Given the equation {equation}, the matching word problem {word_problem}, and the solution {solution}, explain the solution in plain English using the fewest words possible.\"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create chains\n",
    "    equation_solver_chain = equation_solver_prompt | llm\n",
    "    equation_solution_explainer_chain = equation_solution_explainer_prompt | llm\n",
    "    \n",
    "    # Define node functions\n",
    "    def equation_solver_node(input_dict):\n",
    "        equation = input_dict[\"equation\"]\n",
    "        word_problem = input_dict[\"word_problem\"]\n",
    "        solution = equation_solver_chain.invoke({\"equation\": equation, \"word_problem\": word_problem})\n",
    "        # Ensure solution is a string (extract content if it's an AIMessage)\n",
    "        if hasattr(solution, 'content'):\n",
    "            solution = solution.content\n",
    "        return {\"solution\": solution, \"equation\": equation, \"word_problem\": word_problem}\n",
    "    \n",
    "    def equation_solution_explainer_node(input_dict):\n",
    "        equation = input_dict[\"equation\"]\n",
    "        word_problem = input_dict[\"word_problem\"]\n",
    "        solution = input_dict[\"solution\"]\n",
    "        explanation = equation_solution_explainer_chain.invoke({\"equation\": equation, \"word_problem\": word_problem, \"solution\": solution})\n",
    "        # Ensure explanation is a string (extract content if it's an AIMessage)\n",
    "        if hasattr(explanation, 'content'):\n",
    "            explanation = explanation.content\n",
    "        return {\"explanation\": explanation, \"equation\": equation, \"word_problem\": word_problem, \"solution\": solution}\n",
    "    \n",
    "    async def _solve_and_explain(equation: str, word_problem: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Solve an equation and explain the solution using LangGraph.\n",
    "        \n",
    "        Args:\n",
    "            equation: The math equation to solve\n",
    "            word_problem: The word problem that matches the equation\n",
    "            \n",
    "        Returns:\n",
    "            A dictionary containing the equation, word problem, solution, and explanation\n",
    "        \"\"\"\n",
    "        # Create our workflow graph\n",
    "        graph = Graph()\n",
    "        \n",
    "        # Add our processing nodes\n",
    "        graph.add_node(\"Solve Equation\", equation_solver_node)\n",
    "        graph.add_node(\"Explain Solution\", equation_solution_explainer_node)\n",
    "        \n",
    "        # Define the flow between nodes\n",
    "        graph.add_edge(START, \"Solve Equation\")\n",
    "        graph.add_edge(\"Solve Equation\", \"Explain Solution\")\n",
    "        \n",
    "        # Set the finish point to the last node so its output is returned\n",
    "        graph.set_finish_point(\"Explain Solution\")\n",
    "        \n",
    "        # Compile the graph into a runnable workflow\n",
    "        workflow = graph.compile()\n",
    "        \n",
    "        # Run the workflow with our input data\n",
    "        workflow_result = workflow.invoke({\n",
    "            \"equation\": equation,\n",
    "            \"word_problem\": word_problem\n",
    "        })\n",
    "\n",
    "        print(workflow_result)\n",
    "        \n",
    "        # Return the workflow result\n",
    "        return workflow_result\n",
    "    \n",
    "    yield FunctionInfo.from_fn(\n",
    "        _solve_and_explain,\n",
    "        description=\"Solves math equations and provides step-by-step explanations using LangGraph\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. CrewAI Wrapper Component\n",
    "\n",
    "Finally, let's create a wrapper for CrewAI that reviews the solution. This component will:\n",
    "1. Create specialized agents with distinct roles and goals\n",
    "2. Define tasks for each agent to perform\n",
    "3. Coordinate their collaboration through a sequential workflow\n",
    "\n",
    "Let's create this component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workflows/surge_of_agents/src/surge_of_agents/crewai_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/src/surge_of_agents/crewai_wrapper.py\n",
    "import logging\n",
    "import os\n",
    "from typing import Dict, Any\n",
    "\n",
    "from aiq.builder.builder import Builder\n",
    "from aiq.builder.function_info import FunctionInfo\n",
    "from aiq.cli.register_workflow import register_function\n",
    "from aiq.data_models.function import FunctionBaseConfig\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class SolutionReviewerConfig(FunctionBaseConfig, name=\"solution_reviewer\"):\n",
    "    \"\"\"Configuration for the solution reviewer component.\"\"\"\n",
    "    endpoint_url: str = os.getenv(\"NVIDIA_BASE_URL\")\n",
    "    model_name: str = \"meta/llama-3.1-70b-instruct\"\n",
    "    verbose: bool = True\n",
    "\n",
    "@register_function(config_type=SolutionReviewerConfig)\n",
    "async def solution_reviewer(config: SolutionReviewerConfig, builder: Builder):\n",
    "    \"\"\"\n",
    "    A wrapper for CrewAI that reviews math solutions.\n",
    "    \"\"\"\n",
    "    from crewai import Agent, Task, Crew, LLM\n",
    "    import os\n",
    "    \n",
    "    async def _review_solution(equation: str, word_problem: str, solution: str, explanation: str) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Review a math solution using CrewAI.\n",
    "        \n",
    "        Args:\n",
    "            equation: The math equation\n",
    "            word_problem: The word problem that matches the equation\n",
    "            solution: The step-by-step solution\n",
    "            explanation: The explanation of the solution\n",
    "            \n",
    "        Returns:\n",
    "            A dictionary containing the review results\n",
    "        \"\"\"\n",
    "        # Initialize the LLM with the correct format for CrewAI\n",
    "        llm = LLM(\n",
    "            model=f\"nvidia_nim/{config.model_name}\", \n",
    "            base_url=config.endpoint_url,\n",
    "            api_key=os.getenv(\"NVIDIA_API_KEY\")\n",
    "        )\n",
    "        \n",
    "        # Agent 1: Accuracy Checker\n",
    "        accuracy_checker_agent = Agent(\n",
    "            role=\"Accuracy Checker\",\n",
    "            goal=\"Verify the mathematical correctness of the word problem, equation, and solution steps\",\n",
    "            backstory=\"You are a meticulous mathematician with a keen eye for detail. Your expertise lies in ensuring that every calculation and logical step in a math problem is correct, leaving no room for errors. You double-check solutions against the original problem to confirm accuracy.\",\n",
    "            llm=llm,\n",
    "            verbose=config.verbose\n",
    "        )\n",
    "        \n",
    "        # Define the accuracy checking task\n",
    "        accuracy_task = Task(\n",
    "            description=f\"Review the following: word problem '{word_problem}', equation '{equation}', and solution '{solution}'. Verify that the solution steps correctly solve the equation and match the word problem. Output 'Correct' if accurate, or identify any errors if incorrect.\",\n",
    "            expected_output=\"A concise statement confirming accuracy ('Correct') or detailing any errors found.\",\n",
    "            agent=accuracy_checker_agent,\n",
    "        )\n",
    "        \n",
    "        # Agent 2: Clarity Reviewer\n",
    "        clarity_reviewer_agent = Agent(\n",
    "            role=\"Clarity Reviewer\",\n",
    "            goal=\"Ensure the word problem and solution explanation are clear, engaging, and educationally valuable for students\",\n",
    "            backstory=\"You are an experienced educator with a passion for making math accessible and engaging. You excel at evaluating whether problems and explanations are easy to understand, appropriately challenging, and relevant to students' learning needs.\",\n",
    "            llm=llm,\n",
    "            verbose=config.verbose,\n",
    "        )\n",
    "        \n",
    "        # Define the clarity review task\n",
    "        clarity_task = Task(\n",
    "            description=f\"Review the following: word problem '{word_problem}' and solution explanation '{explanation}'. Assess if they are clear, engaging, and suitable for middle school students. Provide feedback, including at least one suggestion for improvement if applicable.\",\n",
    "            expected_output=\"A brief assessment of clarity and educational value, plus one suggestion for enhancement.\",\n",
    "            agent=clarity_reviewer_agent,\n",
    "        )\n",
    "        \n",
    "        # Create a crew with both agents and their tasks\n",
    "        crew = Crew(\n",
    "            agents=[accuracy_checker_agent, clarity_reviewer_agent], \n",
    "            tasks=[accuracy_task, clarity_task], \n",
    "            process=\"sequential\",  # Tasks will be executed in order \n",
    "            verbose=config.verbose\n",
    "        )\n",
    "        \n",
    "        # Execute the full workflow\n",
    "        result = crew.kickoff()\n",
    "        \n",
    "        # Return the review results\n",
    "        return {\n",
    "            \"equation\": equation,\n",
    "            \"word_problem\": word_problem,\n",
    "            \"solution\": solution,\n",
    "            \"explanation\": explanation,\n",
    "            \"review\": result\n",
    "        }\n",
    "    \n",
    "    yield FunctionInfo.from_fn(\n",
    "        _review_solution,\n",
    "        description=\"Reviews math solutions for accuracy and clarity using CrewAI\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Updating the Register File\n",
    "\n",
    "Now that we've created all our wrapper components, we need to update the `register.py` file to import them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting workflows/surge_of_agents/src/surge_of_agents/register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/src/surge_of_agents/register.py\n",
    "# pylint: disable=unused-import\n",
    "# flake8: noqa\n",
    "\n",
    "# Import all wrapper components\n",
    "from surge_of_agents.openai_wrapper import equation_generator\n",
    "from surge_of_agents.langchain_wrapper import word_problem_generator\n",
    "from surge_of_agents.langgraph_wrapper import equation_solver\n",
    "from surge_of_agents.crewai_wrapper import solution_reviewer\n",
    "\n",
    "__all__ = [\n",
    "    \"equation_generator\",\n",
    "    \"word_problem_generator\",\n",
    "    \"equation_solver\",\n",
    "    \"solution_reviewer\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll implement a structured sequential workflow that explicitly manages the data flow between components. This approach ensures proper data passing between tools and provides a clear execution sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3: Running Our Multiframework Workflow\n",
    "\n",
    "### 1. Installing\n",
    "\n",
    "Now let's install our package and test the sequential workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///dli/task/workflows/surge_of_agents\n",
      "  Installing build dependencies ... \u001b[?2done\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: agentiq[langchain,llama-index] in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (1.66.3)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (0.3.25)\n",
      "Requirement already satisfied: langchain_nvidia_ai_endpoints in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (0.3.10)\n",
      "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (0.2.76)\n",
      "Requirement already satisfied: crewai in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (0.95.0)\n",
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.12/site-packages (from surge_of_agents==0.1.0) (2.10.6)\n",
      "\u001b[33mWARNING: agentiq 1.1.0 does not provide the extra 'langchain'\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: agentiq 1.1.0 does not provide the extra 'llama-index'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: aiqtoolkit==v1.1.0 in /usr/local/lib/python3.12/site-packages (from agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: aioboto3>=11.0.0 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (14.3.0)\n",
      "Requirement already satisfied: click~=8.1 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (8.2.1)\n",
      "Requirement already satisfied: colorama~=0.4.6 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.4.6)\n",
      "Requirement already satisfied: expandvars~=1.0 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: fastapi~=0.115.5 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.115.9)\n",
      "Requirement already satisfied: httpx~=0.27 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.28.1)\n",
      "Requirement already satisfied: jinja2~=3.1 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.1.6)\n",
      "Requirement already satisfied: jsonpath-ng~=1.7 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: mcp>=1.0.0 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.9.3)\n",
      "Requirement already satisfied: networkx~=3.4 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.5)\n",
      "Requirement already satisfied: numpy~=1.26 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.26.4)\n",
      "Requirement already satisfied: openinference-semantic-conventions~=0.1.14 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.1.20)\n",
      "Requirement already satisfied: openpyxl~=3.1 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.1.5)\n",
      "Requirement already satisfied: pkginfo~=1.12 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.12.1.2)\n",
      "Requirement already satisfied: platformdirs~=4.3 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (4.3.8)\n",
      "Requirement already satisfied: pymilvus~=2.4 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.5.11)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (6.0.2)\n",
      "Requirement already satisfied: ragas~=0.2.14 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.2.15)\n",
      "Requirement already satisfied: rich~=13.9 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (13.9.4)\n",
      "Requirement already satisfied: uvicorn~=0.32.0 in /usr/local/lib/python3.12/site-packages (from uvicorn[standard]~=0.32.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.32.1)\n",
      "Requirement already satisfied: wikipedia~=1.4 in /usr/local/lib/python3.12/site-packages (from aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.4.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/site-packages (from pydantic->surge_of_agents==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.12/site-packages (from pydantic->surge_of_agents==0.1.0) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.12/site-packages (from pydantic->surge_of_agents==0.1.0) (4.14.0)\n",
      "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.4.4)\n",
      "Requirement already satisfied: auth0-python>=4.7.1 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (4.10.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: chromadb>=0.5.23 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.0.12)\n",
      "Requirement already satisfied: instructor>=1.3.3 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.8.2)\n",
      "Requirement already satisfied: json-repair>=0.25.2 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (0.46.2)\n",
      "Requirement already satisfied: jsonref>=1.1.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: litellm>=1.44.22 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.65.0.post1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.22.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.22.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.22.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.34.1)\n",
      "Requirement already satisfied: pdfplumber>=0.11.4 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (0.11.6)\n",
      "Requirement already satisfied: python-dotenv>=1.0.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: pyvis>=0.3.2 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (0.3.2)\n",
      "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (2024.11.6)\n",
      "Requirement already satisfied: tomli-w>=1.1.0 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: tomli>=2.0.2 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: uv>=0.4.25 in /usr/local/lib/python3.12/site-packages (from crewai->surge_of_agents==0.1.0) (0.7.12)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/site-packages (from openai->surge_of_agents==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/site-packages (from openai->surge_of_agents==0.1.0) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/site-packages (from openai->surge_of_agents==0.1.0) (0.8.2)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/site-packages (from openai->surge_of_agents==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/site-packages (from openai->surge_of_agents==0.1.0) (4.67.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.12/site-packages (from langchain->surge_of_agents==0.1.0) (0.3.65)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.12/site-packages (from langchain->surge_of_agents==0.1.0) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.12/site-packages (from langchain->surge_of_agents==0.1.0) (0.3.45)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/site-packages (from langchain->surge_of_agents==0.1.0) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/site-packages (from langchain->surge_of_agents==0.1.0) (2.32.3)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/site-packages (from langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (3.12.12)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/site-packages (from langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in /usr/local/lib/python3.12/site-packages (from langgraph->surge_of_agents==0.1.0) (2.0.26)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in /usr/local/lib/python3.12/site-packages (from langgraph->surge_of_agents==0.1.0) (0.1.70)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (6.4.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.9.1->langchain_nvidia_ai_endpoints->surge_of_agents==0.1.0) (1.20.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai->surge_of_agents==0.1.0) (3.10)\n",
      "Requirement already satisfied: cryptography>=43.0.1 in /usr/local/lib/python3.12/site-packages (from auth0-python>=4.7.1->crewai->surge_of_agents==0.1.0) (45.0.4)\n",
      "Requirement already satisfied: pyjwt>=2.8.0 in /usr/local/lib/python3.12/site-packages (from auth0-python>=4.7.1->crewai->surge_of_agents==0.1.0) (2.10.1)\n",
      "Requirement already satisfied: urllib3>=2.2.3 in /usr/local/lib/python3.12/site-packages (from auth0-python>=4.7.1->crewai->surge_of_agents==0.1.0) (2.4.0)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.2.2.post1)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (4.7.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.22.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.55b1)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.21.1)\n",
      "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.67.1)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (33.1.0)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (9.1.2)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (3.10.18)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/site-packages (from chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (4.24.0)\n",
      "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.12/site-packages (from fastapi~=0.115.5->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.45.3)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/site-packages (from httpx~=0.27->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/site-packages (from httpx~=0.27->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/site-packages (from httpcore==1.*->httpx~=0.27->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.16.0)\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/site-packages (from instructor>=1.3.3->crewai->surge_of_agents==0.1.0) (0.16)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->surge_of_agents==0.1.0) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain->surge_of_agents==0.1.0) (24.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in /usr/local/lib/python3.12/site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph->surge_of_agents==0.1.0) (1.10.0)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->surge_of_agents==0.1.0) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.17->langchain->surge_of_agents==0.1.0) (0.23.0)\n",
      "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.12/site-packages (from litellm>=1.44.22->crewai->surge_of_agents==0.1.0) (8.7.0)\n",
      "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.12/site-packages (from litellm>=1.44.22->crewai->surge_of_agents==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/site-packages (from openpyxl~=3.1->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai->surge_of_agents==0.1.0) (1.70.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.34.1 in /usr/local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai->surge_of_agents==0.1.0) (1.34.1)\n",
      "Requirement already satisfied: opentelemetry-proto==1.34.1 in /usr/local/lib/python3.12/site-packages (from opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai->surge_of_agents==0.1.0) (1.34.1)\n",
      "Requirement already satisfied: protobuf<6.0,>=5.0 in /usr/local/lib/python3.12/site-packages (from opentelemetry-proto==1.34.1->opentelemetry-exporter-otlp-proto-http>=1.22.0->crewai->surge_of_agents==0.1.0) (5.29.5)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.55b1 in /usr/local/lib/python3.12/site-packages (from opentelemetry-sdk>=1.22.0->crewai->surge_of_agents==0.1.0) (0.55b1)\n",
      "Requirement already satisfied: pdfminer.six==20250327 in /usr/local/lib/python3.12/site-packages (from pdfplumber>=0.11.4->crewai->surge_of_agents==0.1.0) (20250327)\n",
      "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/site-packages (from pdfplumber>=0.11.4->crewai->surge_of_agents==0.1.0) (11.2.1)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in /usr/local/lib/python3.12/site-packages (from pdfplumber>=0.11.4->crewai->surge_of_agents==0.1.0) (4.30.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/site-packages (from pdfminer.six==20250327->pdfplumber>=0.11.4->crewai->surge_of_agents==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: ipython>=5.3.0 in /usr/local/lib/python3.12/site-packages (from pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (9.3.0)\n",
      "Requirement already satisfied: jsonpickle>=1.4.1 in /usr/local/lib/python3.12/site-packages (from pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (4.1.1)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain->surge_of_agents==0.1.0) (3.2.3)\n",
      "Requirement already satisfied: aiobotocore==2.22.0 in /usr/local/lib/python3.12/site-packages (from aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.22.0)\n",
      "Requirement already satisfied: aiofiles>=23.2.1 in /usr/local/lib/python3.12/site-packages (from aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (24.1.0)\n",
      "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/site-packages (from aiobotocore==2.22.0->aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.12.0)\n",
      "Requirement already satisfied: botocore<1.37.4,>=1.37.2 in /usr/local/lib/python3.12/site-packages (from aiobotocore==2.22.0->aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.37.3)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/site-packages (from aiobotocore==2.22.0->aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.9.0.post0)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/site-packages (from aiobotocore==2.22.0->aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.12/site-packages (from aiobotocore==2.22.0->aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.17.2)\n",
      "Requirement already satisfied: boto3<1.37.4,>=1.37.2 in /usr/local/lib/python3.12/site-packages (from aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.37.3)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/site-packages (from build>=1.0.3->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in /usr/local/lib/python3.12/site-packages (from cryptography>=43.0.1->auth0-python>=4.7.1->crewai->surge_of_agents==0.1.0) (1.17.1)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/site-packages (from importlib-metadata>=6.8.0->litellm>=1.44.22->crewai->surge_of_agents==0.1.0) (3.23.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /usr/local/lib/python3.12/site-packages (from ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (5.14.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/site-packages (from jinja2~=3.1->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain->surge_of_agents==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: ply in /usr/local/lib/python3.12/site-packages (from jsonpath-ng~=1.7->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.11)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/site-packages (from jsonschema>=4.19.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.25.1)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.17.0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.6.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (3.2.2)\n",
      "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.10)\n",
      "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/site-packages (from mcp>=1.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: pydantic-settings>=2.5.2 in /usr/local/lib/python3.12/site-packages (from mcp>=1.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.9.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/site-packages (from mcp>=1.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.0.20)\n",
      "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/site-packages (from mcp>=1.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.3.6)\n",
      "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (25.2.10)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.12/site-packages (from onnxruntime>=1.14.1->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.55b1 in /usr/local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.55b1 in /usr/local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.55b1)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.55b1 in /usr/local/lib/python3.12/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.55b1)\n",
      "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.12/site-packages (from opentelemetry-instrumentation-asgi==0.55b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (3.8.1)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (2.2.1)\n",
      "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.12/site-packages (from pymilvus~=2.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (80.9.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /usr/local/lib/python3.12/site-packages (from pymilvus~=2.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (5.10.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /usr/local/lib/python3.12/site-packages (from pymilvus~=2.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.2.3)\n",
      "Requirement already satisfied: milvus-lite>=2.4.0 in /usr/local/lib/python3.12/site-packages (from pymilvus~=2.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.4.12)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/site-packages (from ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.14.4)\n",
      "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/site-packages (from ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.3.24)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/site-packages (from ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.2.14)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/site-packages (from ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.6.0)\n",
      "Requirement already satisfied: diskcache>=5.6.3 in /usr/local/lib/python3.12/site-packages (from ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (5.6.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/site-packages (from rich~=13.9->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.12/site-packages (from tokenizers>=0.13.2->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.33.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/site-packages (from typer>=0.9.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.12/site-packages (from uvicorn[standard]~=0.32.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.6.4)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.12/site-packages (from uvicorn[standard]~=0.32.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.21.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.12/site-packages (from uvicorn[standard]~=0.32.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.0.5)\n",
      "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/site-packages (from uvicorn[standard]~=0.32.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (15.0.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/site-packages (from wikipedia~=1.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (4.13.4)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/site-packages (from cffi>=1.14->cryptography>=43.0.1->auth0-python>=4.7.1->crewai->surge_of_agents==0.1.0) (2.22)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.4.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (4.9.1)\n",
      "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.12/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (6.0.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (2025.5.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.1.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/site-packages (from jedi>=0.16->ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.8.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich~=13.9->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus~=2.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/site-packages (from pandas>=1.2.4->pymilvus~=2.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2025.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/site-packages (from pexpect>4.3->ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.2.13)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/site-packages (from pydantic-settings>=2.5.2->mcp>=1.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.4.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/site-packages (from beautifulsoup4->wikipedia~=1.4->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (2.7)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.12/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.12/site-packages (from datasets->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.12/site-packages (from datasets->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/site-packages (from datasets->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/site-packages (from datasets->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.70.15)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.12/site-packages (from langchain-community->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.6.7)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.12/site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.12/site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.12/site-packages (from stack_data->ipython>=5.3.0->pyvis>=0.3.2->crewai->surge_of_agents==0.1.0) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/site-packages (from sympy->onnxruntime>=1.14.1->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (1.3.0)\n",
      "Requirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.12/site-packages (from boto3<1.37.4,>=1.37.2->aiobotocore[boto3]==2.22.0->aioboto3>=11.0.0->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.11.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (0.9.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb>=0.5.23->crewai->surge_of_agents==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community->ragas~=0.2.14->aiqtoolkit==v1.1.0->agentiq[langchain,llama-index]->surge_of_agents==0.1.0) (1.1.0)\n",
      "Building wheels for collected packages: surge_of_agents\n",
      "  Building editable for surge_of_agents (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for surge_of_agents: filename=surge_of_agents-0.1.0-0.editable-py3-none-any.whl size=1707 sha256=dff07818ad837121a065db426cfbb566c2d21bc103e7c067f82e5f3e848f5eec\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-l1edy92w/wheels/de/1c/72/d06c5d412056b9900f0be5d9b78596dd8f269d6a437ebafecd\n",
      "Successfully built surge_of_agents\n",
      "Installing collected packages: surge_of_agents\n",
      "Successfully installed surge_of_agents-0.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -e workflows/surge_of_agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating the Workflow Configuration\n",
    "\n",
    "Now we'll create a configuration file that defines our sequential workflow. First, create a directory for the config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p workflows/surge_of_agents/configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll write the config file using the various frameworks we wrapped as AgentIQ components above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing workflows/surge_of_agents/configs/sequential_config.yml\n"
     ]
    }
   ],
   "source": [
    "%%writefile workflows/surge_of_agents/configs/sequential_config.yml\n",
    "general:\n",
    "  uvloop: true\n",
    "  telemetry:\n",
    "    tracing:\n",
    "      phoenix:\n",
    "          _type: phoenix\n",
    "          endpoint: http://phoenix:6006/v1/traces\n",
    "          project: surge_of_agents\n",
    "\n",
    "llms:\n",
    "  nim_llm:\n",
    "    _type: nim\n",
    "    model_name: meta/llama-3.1-70b-instruct\n",
    "    temperature: 0.7\n",
    "    max_tokens: 1000\n",
    "    base_url: $NVIDIA_BASE_URL\n",
    "    api_key: $NVIDIA_API_KEY\n",
    "    \n",
    "functions:\n",
    "  equation_generator:\n",
    "    _type: equation_generator\n",
    "    llm_name: nim_llm\n",
    "    \n",
    "  word_problem_generator:\n",
    "    _type: word_problem_generator\n",
    "    llm_name: nim_llm\n",
    "    \n",
    "  equation_solver:\n",
    "    _type: equation_solver\n",
    "    llm_name: nim_llm\n",
    "\n",
    "  solution_reviewer:\n",
    "    _type: solution_reviewer\n",
    "    llm_name: nim_llm\n",
    "\n",
    "workflow:\n",
    "  _type: react_agent\n",
    "  llm_name: nim_llm\n",
    "  system_prompt: |\n",
    "    You are a helpful assistant that follows a sequential workflow to create and solve math problems.\n",
    "\n",
    "    You need to perform the following steps in order:\n",
    "    1. Generate a math equation\n",
    "    2. Create a word problem based on the equation\n",
    "    3. Solve the equation\n",
    "    4. Review the solution\n",
    "\n",
    "    You have access to the following tools:\n",
    "\n",
    "    {tools}\n",
    "\n",
    "    You may respond in one of two formats.\n",
    "    Use the following format exactly to ask the human to use a tool:\n",
    "\n",
    "    Question: the input question you must answer\n",
    "    Thought: you should always think about what to do\n",
    "    Action: the action to take, should be one of [{tool_names}]\n",
    "    Action Input: the input to the action (if there is no required input, include \"Action Input: None\")  \n",
    "    Observation: wait for the human to respond with the result from the tool, do not assume the response\n",
    "\n",
    "    ... (this Thought/Action/Action Input/Observation can repeat N times. If you do not need to use a tool, or after asking the human to use any tools and waiting for the human to respond, you might know the final answer.)\n",
    "    Use the following format once you have the final answer:\n",
    "\n",
    "    Thought: I now know the final answer\n",
    "    Final Answer: the equation, word problem, solution, and explanation\n",
    "  \n",
    "  tool_names:\n",
    "    - equation_generator\n",
    "    - word_problem_generator\n",
    "    - equation_solver\n",
    "    - solution_reviewer\n",
    "  verbose: true\n",
    "  retry_parsing_errors: true\n",
    "  max_retries: 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Observability\n",
    "\n",
    "If you want, you can open up Phoenix to see the entire agentic flow in the next cell, since we instrumented our config for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const href = window.location.hostname;\n",
       "let a = document.createElement('a');\n",
       "let link = document.createTextNode('Click here to open Phoenix!');\n",
       "a.appendChild(link);\n",
       "a.href = \"http://\" + href + \"/phoenix\";\n",
       "a.style.color = \"navy\"\n",
       "a.target = \"_blank\"\n",
       "element.append(a);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "const href = window.location.hostname;\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Click here to open Phoenix!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href + \"/phoenix\";\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Running the Workflow\n",
    "\n",
    "Now, at long last, we can run our workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-11 09:07:29,003 - aiq.runtime.loader - WARNING - Loading module 'aiq.agent.register' from entry point 'aiq_agents' took a long time (328.452110 ms). Ensure all imports are inside your registered functions.\n",
      "2025-07-11 09:07:29,147 - aiq.cli.commands.start - INFO - Starting AIQ Toolkit from config file: 'workflows/surge_of_agents/configs/sequential_config.yml'\n",
      "2025-07-11 09:07:29,151 - aiq.cli.commands.start - WARNING - The front end type in the config file (fastapi) does not match the command name (console). Overwriting the config file front end.\n",
      "2025-07-11 09:07:29,172 - phoenix.config - INFO - 📋 Ensuring phoenix working directory: /root/.phoenix\n",
      "2025-07-11 09:07:29,181 - phoenix.inferences.inferences - INFO - Dataset: phoenix_inferences_4922afb7-dc8b-4c6d-ba6c-62c747c8bbaa initialized\n",
      "\n",
      "Configuration Summary:\n",
      "--------------------\n",
      "Workflow Type: react_agent\n",
      "Number of Functions: 4\n",
      "Number of LLMs: 1\n",
      "Number of Embedders: 0\n",
      "Number of Memory: 0\n",
      "Number of Retrievers: 0\n",
      "\n",
      "2025-07-11 09:07:35,440 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Create a math problem about for pre-algebra students\n",
      "\u001b[36mAgent's thoughts: \n",
      "Thought: To create a math problem for pre-algebra students, I need to generate a math equation suitable for their level.\n",
      "\n",
      "Action: equation_generator\n",
      "Action Input: {'student_level': 'pre-algebra'}\n",
      "\n",
      "\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:36,032 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: equation_generator\n",
      "\u001b[33mTool's input: {\"student_level\": \"pre-algebra\"}\n",
      "\u001b[36mTool's response: \n",
      "{'equation': '2x + 7 = 19'}\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:37,373 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Create a math problem about for pre-algebra students\n",
      "\u001b[36mAgent's thoughts: \n",
      "Thought: Now that I have the equation, I need to create a word problem that corresponds to this equation to make it more relatable for pre-algebra students.\n",
      "\n",
      "Action: word_problem_generator\n",
      "Action Input: {'equation': '2x + 7 = 19'}\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:38,855 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: word_problem_generator\n",
      "\u001b[33mTool's input: {\"equation\": \"2x + 7 = 19\"}\n",
      "\u001b[36mTool's response: \n",
      "{'equation': '2x + 7 = 19', 'word_problem': 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?'}\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:41,083 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Create a math problem about for pre-algebra students\n",
      "\u001b[36mAgent's thoughts: \n",
      "Thought: Now that I have the equation and the word problem, I can solve the equation to find the value of x.\n",
      "\n",
      "Action: equation_solver\n",
      "Action Input: {'equation': '2x + 7 = 19', 'word_problem': 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?'}\u001b[39m\n",
      "------------------------------\n",
      "{'explanation': 'Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.', 'equation': '2x + 7 = 19', 'word_problem': 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?', 'solution': 'Here are the mathematical steps to solve the equation:\\n\\n2x + 7 = 19\\n2x + 7 - 7 = 19 - 7\\n2x = 12\\n2x / 2 = 12 / 2\\nx = 6'}\n",
      "2025-07-11 09:07:43,420 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: equation_solver\n",
      "\u001b[33mTool's input: {\"equation\": \"2x + 7 = 19\", \"word_problem\": \"Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?\"}\n",
      "\u001b[36mTool's response: \n",
      "{'explanation': 'Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.', 'equation': '2x + 7 = 19', 'word_problem': 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?', 'solution': 'Here are the mathematical steps to solve the equation:\\n\\n2x + 7 = 19\\n2x + 7 - 7 = 19 - 7\\n2x = 12\\n2x / 2 = 12 / 2\\nx = 6'}\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:47,305 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Create a math problem about for pre-algebra students\n",
      "\u001b[36mAgent's thoughts: \n",
      "Thought: Now that I have the solution and explanation, I can review the solution to ensure it's accurate and clear.\n",
      "\n",
      "Action: solution_reviewer\n",
      "Action Input: {'equation': '2x + 7 = 19', 'word_problem': 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?', 'solution': 'Here are the mathematical steps to solve the equation:\\n\\n2x + 7 = 19\\n2x + 7 - 7 = 19 - 7\\n2x = 12\\n2x / 2 = 12 / 2\\nx = 6', 'explanation': 'Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.'}\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:47,311 - opentelemetry.trace - WARNING - Overriding of current TracerProvider is not allowed\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAccuracy Checker\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mReview the following: word problem 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?', equation '2x + 7 = 19', and solution 'Here are the mathematical steps to solve the equation:\n",
      "\n",
      "2x + 7 = 19\n",
      "2x + 7 - 7 = 19 - 7\n",
      "2x = 12\n",
      "2x / 2 = 12 / 2\n",
      "x = 6'. Verify that the solution steps correctly solve the equation and match the word problem. Output 'Correct' if accurate, or identify any errors if incorrect.\u001b[00m\n",
      "\u001b[92m09:07:47 - LiteLLM:INFO\u001b[0m: utils.py:3056 - \n",
      "LiteLLM completion() model= meta/llama-3.1-70b-instruct; provider = nvidia_nim\n",
      "2025-07-11 09:07:47,331 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= meta/llama-3.1-70b-instruct; provider = nvidia_nim\n",
      "\u001b[92m09:07:50 - LiteLLM:INFO\u001b[0m: utils.py:1165 - Wrapper: Completed Call, calling success_handler\n",
      "2025-07-11 09:07:50,972 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:07:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "2025-07-11 09:07:50,973 - LiteLLM - INFO - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "\u001b[92m09:07:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "2025-07-11 09:07:50,974 - LiteLLM - INFO - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAccuracy Checker\u001b[00m\u001b[92m09:07:50 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Correct.\n",
      "\n",
      "The word problem states that Tom starts with $7, needs a total of $19, and earns $2 per lawn. The equation 2x + 7 = 19 accurately represents the situation, where x is the number of lawns Tom needs to mow.\n",
      "\n",
      "The solution steps provided are mathematically correct:\n",
      "\n",
      "1. 2x + 7 = 19 (initial equation)\n",
      "2. 2x + 7 - 7 = 19 - 7 (subtracting 7 from both sides)\n",
      "3. 2x = 12 (simplifying)\n",
      "4. 2x / 2 = 12 / 2 (dividing both sides by 2)\n",
      "5. x = 6 (solving for x)\n",
      "\n",
      "The solution correctly yields x = 6, indicating that Tom needs to mow 6 lawns to earn the additional $12 required to meet his goal of $19. The solution matches the word problem and is free from errors.\u001b[00m\n",
      "\n",
      "2025-07-11 09:07:50,979 - LiteLLM - INFO - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mClarity Reviewer\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mReview the following: word problem 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?' and solution explanation 'Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.'. Assess if they are clear, engaging, and suitable for middle school students. Provide feedback, including at least one suggestion for improvement if applicable.\u001b[00m\n",
      "\u001b[92m09:07:50 - LiteLLM:INFO\u001b[0m: utils.py:3056 - \n",
      "LiteLLM completion() model= meta/llama-3.1-70b-instruct; provider = nvidia_nim\n",
      "2025-07-11 09:07:50,981 - LiteLLM - INFO - \n",
      "LiteLLM completion() model= meta/llama-3.1-70b-instruct; provider = nvidia_nim\n",
      "\u001b[92m09:07:54 - LiteLLM:INFO\u001b[0m: utils.py:1165 - Wrapper: Completed Call, calling success_handler\n",
      "2025-07-11 09:07:54,354 - LiteLLM - INFO - Wrapper: Completed Call, calling success_handler\n",
      "\u001b[92m09:07:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "2025-07-11 09:07:54,354 - LiteLLM - INFO - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mClarity Reviewer\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The given word problem and solution explanation are generally clear and suitable for middle school students. The word problem effectively conveys a real-life scenario, making it relatable and engaging for students. The solution explanation accurately represents the step-by-step process required to solve the problem, aligning with the mathematical equation 2x + 7 = 19.\n",
      "\n",
      "However, to further enhance the clarity and educational value of the solution explanation, I suggest including more descriptive language to help students understand the reasoning behind each step. For instance, instead of simply stating \"Subtract $7 from both sides,\" the explanation could be rephrased as \"To isolate the term with the variable (2x), we subtract $7 from both sides of the equation, which is essentially subtracting the initial amount Tom already has from both the left and right sides of the equation.\"\n",
      "\n",
      "This suggested modification aims to provide additional context and promote a deeper understanding of the mathematical operations involved, ultimately making the solution more accessible and engaging for middle school students.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[92m09:07:54 - LiteLLM:INFO\u001b[0m: cost_calculator.py:591 - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "2025-07-11 09:07:54,355 - LiteLLM - INFO - selected model name for cost calculation: nvidia_nim/meta/llama-3.1-70b-instruct\n",
      "2025-07-11 09:07:54,357 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[37mCalling tools: solution_reviewer\n",
      "\u001b[33mTool's input: {\"equation\": \"2x + 7 = 19\", \"word_problem\": \"Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?\", \"solution\": \"Here are the mathematical steps to solve the equation:\\n\\n2x + 7 = 19\\n2x + 7 - 7 = 19 - 7\\n2x = 12\\n2x / 2 = 12 / 2\\nx = 6\", \"explanation\": \"Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.\"}\n",
      "\u001b[36mTool's response: \n",
      "{'equation': '2x + 7 = 19', 'word_problem': 'Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?', 'solution': 'Here are the mathematical steps to solve the equation:\\n\\n2x + 7 = 19\\n2x + 7 - 7 = 19 - 7\\n2x = 12\\n2x / 2 = 12 / 2\\nx = 6', 'explanation': 'Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.', 'review': CrewOutput(raw='The given word problem and solution explanation are generally clear and suitable for middle school students. The word problem effectively conveys a real-life scenario, making it relatable and engaging for students. The solution explanation accurately represents the step-by-step process required to solve the problem, aligning with the mathematical equation 2x + ...\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:58,192 - aiq.agent.react_agent.agent - INFO - \n",
      "------------------------------\n",
      "[AGENT]\n",
      "\u001b[33mAgent input: Create a math problem about for pre-algebra students\n",
      "\u001b[36mAgent's thoughts: \n",
      "Thought: I now know the final answer\n",
      "\n",
      "Final Answer: Equation: 2x + 7 = 19, Word Problem: Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?, Solution: Here are the mathematical steps to solve the equation:\\n\\n2x + 7 = 19\\n2x + 7 - 7 = 19 - 7\\n2x = 12\\n2x / 2 = 12 / 2\\nx = 6, Explanation: Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.\u001b[39m\n",
      "------------------------------\n",
      "2025-07-11 09:07:58,194 - aiq.front_ends.console.console_front_end_plugin - INFO - \n",
      "--------------------------------------------------\n",
      "\u001b[32mWorkflow Result:\n",
      "['Equation: 2x + 7 = 19, Word Problem: Tom has been saving money for a new bike and has $7 in his piggy bank. He plans to mow lawns to earn more money and expects to earn $2 for each lawn he mows. If he needs a total of $19 to buy the bike, how many lawns (x) does Tom need to mow to have enough money?, Solution: Here are the mathematical steps to solve the equation:\\\\n\\\\n2x + 7 = 19\\\\n2x + 7 - 7 = 19 - 7\\\\n2x = 12\\\\n2x / 2 = 12 / 2\\\\nx = 6, Explanation: Tom has $7. He needs $19. He earns $2 per lawn. Subtract $7 from both sides. He needs $12 more. Divide by $2 (lawns). He needs to mow 6 lawns.']\u001b[39m\n",
      "--------------------------------------------------\n",
      "\u001b[0m\u001b[0m"
     ]
    }
   ],
   "source": [
    "!aiq run --config_file workflows/surge_of_agents/configs/sequential_config.yml --input \"Create a math problem about for pre-algebra students\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to integrate multiple AI frameworks using AgentIQ.\n",
    "\n",
    "This approach showcases the benefits of AgentIQ:\n",
    "\n",
    "- **Framework Interoperability**: Seamlessly integrate OpenAI, LangChain, LangGraph, and CrewAI.\n",
    "- **Workflow Management**: Orchestrate complex workflows with proper data handling.\n",
    "- **Deployment Options**: Deploy workflows as APIs, CLIs, or web applications.\n",
    "- **Extensibility**: Easily add new components or modify existing ones."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
